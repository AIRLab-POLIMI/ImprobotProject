{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from deepface import DeepFace\n",
    "import cv2\n",
    "import time\n",
    "import numpy as np\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "FILE=  \"./snap.png\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "img = cv2.imread(FILE)\n",
    "TARGET_FRAME_H = 480\n",
    "h, w, _  = img.shape\n",
    "red = cv2.resize(img, (TARGET_FRAME_H, int(TARGET_FRAME_H*h/w)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "backends = [\"opencv\",\"ssd\", \"retinaface\", \"mtcnn\", \"dlib\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_time(backend):\n",
    "    times = []\n",
    "    for _ in range(100):\n",
    "        s = time.time()\n",
    "        _ = DeepFace.detectFace(red, detector_backend=backend)\n",
    "        e = time.time()\n",
    "        times.append(e-s)\n",
    "    return np.mean(times), np.std(times)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "  0%|          | 0/5 [00:47<?, ?it/s]\n",
      "\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "100%|██████████| 5/5 [04:23<00:00, 52.66s/it]\n"
     ]
    }
   ],
   "source": [
    "results = [(b, *get_time(b)) for b in tqdm(backends)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('opencv', 0.07655892133712769, 0.0028219315573466664),\n",
       " ('ssd', 0.04864974021911621, 0.005127733076269846),\n",
       " ('retinaface', 1.6307357454299927, 0.2659187709625731),\n",
       " ('mtcnn', 0.44707278728485106, 0.043126353276591665),\n",
       " ('dlib', 0.42969278573989866, 0.03132568673026541)]"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# OpenCV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "face_cascade = cv2.CascadeClassifier('haarcascade_frontalface_default.xml')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ocv_time = []\n",
    "for _ in tqdm(range(100)):\n",
    "    s = time.time()\n",
    "    face = face_cascade.detectMultiScale(img, 1.1, 4)\n",
    "    e = time.time()\n",
    "    ocv_time.append(e-s)\n",
    "print(f\"opencv - mean: {np.mean(ocv_time)}, std: {np.std(ocv_time)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Dlib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import dlib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "face_detector = dlib.get_frontal_face_detector()\n",
    "img = cv2.imread(FILE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 100/100 [00:07<00:00, 14.15it/s]\n"
     ]
    }
   ],
   "source": [
    "dlib_times = []\n",
    "TARGET_FRAME_H = 480\n",
    "h, w, _  = img.shape\n",
    "red = cv2.resize(img, (TARGET_FRAME_H, int(TARGET_FRAME_H*h/w)))\n",
    "for _ in tqdm(range(100)):\n",
    "    s = time.time()\n",
    "    _ = face_detector(red, 1)\n",
    "    e = time.time()\n",
    "    dlib_times.append(e-s)\n",
    "dlib_mean = np.mean(dlib_times)\n",
    "dlib_std = np.std(dlib_times)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.07036459922790528, 0.005954892001096505)"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dlib_mean ,dlib_std"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cv2.imwrite(\"test.png\", img)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 100/100 [00:08<00:00, 12.09it/s]\n"
     ]
    }
   ],
   "source": [
    "ssd_times = []\n",
    "for _ in tqdm(range(100)):\n",
    "    s = time.time()\n",
    "    _ = DeepFace.analyze(img, actions = ['emotion'])\n",
    "    e = time.time()\n",
    "    ssd_times.append(e-s)\n",
    "ssd_mean = np.mean(ssd_times)\n",
    "ssd_std = np.std(ssd_times)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.04652724504470825, 0.009975967952996665)"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(ssd_mean, ssd_std)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 100/100 [00:02<00:00, 40.10it/s]\n"
     ]
    }
   ],
   "source": [
    "find_times = []\n",
    "for _ in tqdm(range(100)):\n",
    "    s = time.time()\n",
    "    find = DeepFace.detectFace(img, detector_backend=\"ssd\", align=False)\n",
    "    e = time.time()\n",
    "    find_times.append(e-s)\n",
    "find_mean = np.mean(find_times)\n",
    "find_std = np.std(find_times)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.024827897548675537, 0.003196199845505427)"
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(find_mean, find_std)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cv2.imwrite(\"find.jpg\", find*255)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# PAZ"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "from EmotionProcessor import EmotionProcessor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [],
   "source": [
    "ep = EmotionProcessor()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [],
   "source": [
    "def paz_pipeline(backend):\n",
    "    paz_times = []\n",
    "    for _ in tqdm(range(20)):\n",
    "        s = time.time()\n",
    "        find = DeepFace.detectFace(img, detector_backend=backend, align=False)\n",
    "        #find_rgb = cv2.cvtColor(find*255, cv2.COLOR_BGR2RGB)\n",
    "        _ = ep(find*255)\n",
    "        e = time.time()\n",
    "        paz_times.append(e-s)\n",
    "    paz_mean = np.mean(paz_times)\n",
    "    paz_std = np.std(paz_times)\n",
    "    return paz_mean, paz_std"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 20/20 [00:01<00:00, 13.00it/s]\n",
      "100%|██████████| 20/20 [00:10<00:00,  1.95it/s]\n",
      "100%|██████████| 20/20 [00:35<00:00,  1.75s/it]\n",
      "100%|██████████| 20/20 [00:00<00:00, 20.13it/s]\n"
     ]
    }
   ],
   "source": [
    "results_paz = [(b, *paz_pipeline(b)) for b in backends]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('opencv', 0.07658860683441163, 0.0038083545801218407),\n",
       " ('dlib', 0.5125818610191345, 0.07607236507055605),\n",
       " ('retinaface', 1.7534725785255432, 0.6074308977522134),\n",
       " ('ssd', 0.04941911697387695, 0.002139623092962623)]"
      ]
     },
     "execution_count": 83,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results_paz"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Eye contact"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [],
   "source": [
    "from EyeContactDetector import EyeContactDetector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loading saved model weights\n"
     ]
    }
   ],
   "source": [
    "ec = EyeContactDetector()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [],
   "source": [
    "def eye_pipeline(backend):\n",
    "    paz_times = []\n",
    "    for _ in tqdm(range(20)):\n",
    "        s = time.time()\n",
    "        find = DeepFace.detectFace(img, detector_backend=backend, align=False)\n",
    "        #find_rgb = cv2.cvtColor(find*255, cv2.COLOR_BGR2RGB)\n",
    "        _ = ec.detect_eye_contact_on_face(find*255)\n",
    "        e = time.time()\n",
    "        paz_times.append(e-s)\n",
    "    paz_mean = np.mean(paz_times)\n",
    "    paz_std = np.std(paz_times)\n",
    "    return paz_mean, paz_std"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 20/20 [00:01<00:00, 12.10it/s]\n",
      "100%|██████████| 20/20 [00:09<00:00,  2.05it/s]\n",
      "100%|██████████| 20/20 [00:32<00:00,  1.63s/it]\n",
      "100%|██████████| 20/20 [00:00<00:00, 20.74it/s]\n"
     ]
    }
   ],
   "source": [
    "results_eye = [(b, *paz_pipeline(b)) for b in backends]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('opencv', 0.08226438760757446, 0.010470864126201565),\n",
       " ('dlib', 0.4861815690994263, 0.012266820965071461),\n",
       " ('retinaface', 1.6252570152282715, 0.05895252293748639),\n",
       " ('ssd', 0.048024463653564456, 0.004167891071739218)]"
      ]
     },
     "execution_count": 89,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results_eye"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_on_video(backend):\n",
    "    VID = \"test_face.mov\"\n",
    "    cap = cv2.VideoCapture(VID)\n",
    "    ret = True\n",
    "    missing_frames = 0\n",
    "    frames = 0\n",
    "    while ret and frames < 100:\n",
    "        ret, frame = cap.read()\n",
    "        if frame is None:\n",
    "            break\n",
    "        try:\n",
    "            find = DeepFace.detectFace(frame, detector_backend=backend, align=False)\n",
    "            #find_rgb = cv2.cvtColor(find*255, cv2.COLOR_BGR2RGB)\n",
    "            _ = ep(find*255)\n",
    "            print(\"detected\")\n",
    "        except:\n",
    "            print(\"face not found\")\n",
    "            missing_frames += 1 \n",
    "        frames += 1\n",
    "    return missing_frames\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "detected\n",
      "detected\n",
      "detected\n",
      "detected\n",
      "detected\n",
      "detected\n",
      "detected\n",
      "detected\n",
      "detected\n",
      "detected\n",
      "detected\n",
      "detected\n",
      "detected\n",
      "detected\n",
      "detected\n",
      "detected\n",
      "detected\n",
      "detected\n",
      "detected\n",
      "detected\n",
      "detected\n",
      "detected\n",
      "detected\n",
      "detected\n",
      "detected\n",
      "detected\n",
      "detected\n",
      "detected\n",
      "detected\n",
      "detected\n",
      "detected\n",
      "detected\n",
      "detected\n",
      "detected\n",
      "detected\n",
      "detected\n",
      "detected\n",
      "detected\n",
      "detected\n",
      "detected\n",
      "detected\n",
      "detected\n",
      "detected\n",
      "detected\n",
      "detected\n",
      "detected\n",
      "detected\n",
      "detected\n",
      "detected\n",
      "detected\n",
      "detected\n",
      "detected\n",
      "detected\n",
      "detected\n",
      "detected\n",
      "detected\n",
      "detected\n",
      "detected\n",
      "detected\n",
      "detected\n",
      "detected\n",
      "detected\n",
      "detected\n",
      "detected\n",
      "detected\n",
      "detected\n",
      "detected\n",
      "detected\n",
      "detected\n",
      "detected\n",
      "detected\n",
      "detected\n",
      "detected\n",
      "detected\n",
      "detected\n",
      "detected\n",
      "detected\n",
      "detected\n",
      "detected\n",
      "detected\n",
      "detected\n",
      "detected\n",
      "detected\n",
      "detected\n",
      "detected\n",
      "detected\n",
      "detected\n",
      "face not found\n",
      "detected\n",
      "face not found\n",
      "detected\n",
      "face not found\n",
      "face not found\n",
      "detected\n",
      "face not found\n",
      "face not found\n",
      "face not found\n",
      "face not found\n",
      "face not found\n",
      "face not found\n",
      "detected\n",
      "detected\n",
      "detected\n",
      "detected\n",
      "detected\n",
      "detected\n",
      "detected\n",
      "detected\n",
      "detected\n",
      "detected\n",
      "detected\n",
      "detected\n",
      "detected\n",
      "detected\n",
      "detected\n",
      "detected\n",
      "detected\n",
      "detected\n",
      "detected\n",
      "detected\n",
      "detected\n",
      "detected\n",
      "detected\n",
      "detected\n",
      "detected\n",
      "detected\n",
      "detected\n",
      "detected\n",
      "detected\n",
      "detected\n",
      "detected\n",
      "detected\n",
      "detected\n",
      "detected\n",
      "detected\n",
      "detected\n",
      "detected\n",
      "detected\n",
      "detected\n",
      "detected\n",
      "detected\n",
      "detected\n",
      "detected\n",
      "detected\n",
      "detected\n",
      "detected\n",
      "detected\n",
      "detected\n",
      "detected\n",
      "detected\n",
      "detected\n",
      "detected\n",
      "detected\n",
      "detected\n",
      "detected\n",
      "detected\n",
      "detected\n",
      "detected\n",
      "detected\n",
      "detected\n",
      "detected\n",
      "detected\n",
      "detected\n",
      "detected\n",
      "detected\n",
      "detected\n",
      "detected\n",
      "detected\n",
      "detected\n",
      "detected\n",
      "detected\n",
      "detected\n",
      "detected\n",
      "detected\n",
      "detected\n",
      "detected\n",
      "detected\n",
      "detected\n",
      "detected\n",
      "detected\n",
      "detected\n",
      "detected\n",
      "detected\n",
      "detected\n",
      "detected\n",
      "detected\n",
      "detected\n",
      "detected\n",
      "detected\n",
      "detected\n",
      "detected\n",
      "detected\n",
      "detected\n",
      "detected\n",
      "detected\n",
      "detected\n",
      "detected\n",
      "detected\n",
      "detected\n",
      "detected\n"
     ]
    }
   ],
   "source": [
    "frames = [(b, run_on_video(b)) for b in backends]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('opencv', 10), ('ssd', 0)]"
      ]
     },
     "execution_count": 98,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "frames"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "767d51c1340bd893661ea55ea3124f6de3c7a262a8b4abca0554b478b1e2ff90"
  },
  "kernelspec": {
   "display_name": "Python 3.8.10 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
